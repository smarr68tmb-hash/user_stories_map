# üöÄ RabbitMQ + Wireframe Generation: –ü–û–õ–ù–û–ï –†–£–ö–û–í–û–î–°–¢–í–û

**–í–µ—Ä—Å–∏—è:** 1.0.0
**–î–∞—Ç–∞:** 2025-12-01
**–ê–≤—Ç–æ—Ä:** AI Assistant
**–ü—Ä–æ–µ–∫—Ç:** AI User Story Mapper

---

## üìë –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

1. [–í–≤–µ–¥–µ–Ω–∏–µ –∏ –û–±–∑–æ—Ä](#–≤–≤–µ–¥–µ–Ω–∏–µ-–∏-–æ–±–∑–æ—Ä)
2. [–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–∏—Å—Ç–µ–º—ã](#–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞-—Å–∏—Å—Ç–µ–º—ã)
3. [–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è](#–ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ-—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è)
4. [Phase 1: RabbitMQ Setup](#phase-1-rabbitmq-setup)
5. [Phase 2: Backend Infrastructure](#phase-2-backend-infrastructure)
6. [Phase 3: Workers Implementation](#phase-3-workers-implementation)
7. [Phase 4: Frontend Integration](#phase-4-frontend-integration)
8. [Phase 5: Testing](#phase-5-testing)
9. [Phase 6: Deployment](#phase-6-deployment)
10. [Phase 7: Monitoring & Maintenance](#phase-7-monitoring--maintenance)
11. [Troubleshooting](#troubleshooting)
12. [Best Practices](#best-practices)
13. [Future Enhancements](#future-enhancements)

---

## 1. –í–≤–µ–¥–µ–Ω–∏–µ –∏ –û–±–∑–æ—Ä

### 1.1. –¶–µ–ª–∏ –ø—Ä–æ–µ–∫—Ç–∞

–†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –¥–ª—è AI User Story Mapper —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º RabbitMQ –¥–ª—è:

1. **–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ AI –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏** –∫–∞—Ä—Ç (—Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è —Ñ—É–Ω–∫—Ü–∏—è)
   - –†–∞–∑–≥—Ä—É–∑–∫–∞ HTTP —Å–µ—Ä–≤–µ—Ä–∞
   - –£–ª—É—á—à–µ–Ω–∏–µ user experience (–Ω–µ—Ç –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –Ω–∞ 60 —Å–µ–∫)
   - –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è workers

2. **–ù–æ–≤–æ–π —Ñ–∏—á–∏: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è UI –ø—Ä–æ—Ç–æ—Ç–∏–ø–æ–≤/wireframes**
   - AI-powered –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö mockups
   - –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–∞–∑–Ω—ã—Ö —Å—Ç–∏–ª–µ–π (low/high fidelity)
   - –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –ø—Ä–æ–µ–∫—Ç–æ–º –∏ User Stories

### 1.2. –ü–æ—á–µ–º—É RabbitMQ?

**–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞–º–∏:**

| –ö—Ä–∏—Ç–µ—Ä–∏–π | RabbitMQ | Kafka | Redis Queues | Celery |
|----------|----------|-------|--------------|--------|
| –°–ª–æ–∂–Ω–æ—Å—Ç—å setup | ‚≠ê‚≠ê –ü—Ä–æ—Å—Ç–æ–π | ‚≠ê‚≠ê‚≠ê‚≠ê –°–ª–æ–∂–Ω—ã–π | ‚≠ê –û—á–µ–Ω—å –ø—Ä–æ—Å—Ç–æ–π | ‚≠ê‚≠ê –ü—Ä–æ—Å—Ç–æ–π |
| Message ordering | ‚úÖ –î–∞ | ‚úÖ –î–∞ (–≤ partition) | ‚ö†Ô∏è –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ | ‚ö†Ô∏è –ù–µ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç—Å—è |
| Message persistence | ‚úÖ –î–∞ | ‚úÖ –î–∞ | ‚ö†Ô∏è –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ | ‚úÖ –î–∞ |
| Priority queues | ‚úÖ –î–∞ | ‚ùå –ù–µ—Ç | ‚ùå –ù–µ—Ç | ‚úÖ –î–∞ |
| Dead letter queues | ‚úÖ –î–∞ | ‚ùå –ù–µ—Ç | ‚ùå –ù–µ—Ç | ‚úÖ –î–∞ |
| Management UI | ‚úÖ –û—Ç–ª–∏—á–Ω—ã–π | ‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç –¥–æ–ø. tools | ‚ùå –ù–µ—Ç | ‚ö†Ô∏è Flower (–æ—Ç–¥–µ–ª—å–Ω–æ) |
| Free hosting | ‚úÖ CloudAMQP 1M msg | ‚úÖ Upstash 10K | ‚úÖ Upstash unlimited | ‚ùå –ù—É–∂–µ–Ω broker |
| Best for | Task queues | Event streaming | Simple queues | Python tasks |
| **–î–ª—è USM –ø—Ä–æ–µ–∫—Ç–∞** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |

**–í—ã–±–æ—Ä:** RabbitMQ –∏–¥–µ–∞–ª–µ–Ω –¥–ª—è –Ω–∞—à–µ–≥–æ use case - task queue processing —Å –≥–∞—Ä–∞–Ω—Ç–∏—è–º–∏ –¥–æ—Å—Ç–∞–≤–∫–∏.

### 1.3. –ß—Ç–æ –ø–æ–ª—É—á–∏–º –ø–æ—Å–ª–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

**–î–æ (—Ç–µ–∫—É—â–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞):**
```
User ‚Üí POST /generate-map ‚Üí [WAIT 60 seconds] ‚Üí Response
                                   ‚Üì
                            AI API (Groq/OpenAI)
                                   ‚Üì
                            Save to PostgreSQL
```

**–ü–æ—Å–ª–µ (—Å RabbitMQ):**
```
User ‚Üí POST /generate-map-async ‚Üí 202 Accepted (job_id) [1 second]
                                        ‚Üì
                                  RabbitMQ Queue
                                        ‚Üì
                                   AI Worker (background)
                                        ‚Üì
                              WebSocket notification
                                        ‚Üì
                              User: "–ö–∞—Ä—Ç–∞ –≥–æ—Ç–æ–≤–∞!"
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- ‚úÖ User –Ω–µ –∂–¥–µ—Ç 60 —Å–µ–∫—É–Ω–¥
- ‚úÖ HTTP —Å–µ—Ä–≤–µ—Ä –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç—Å—è
- ‚úÖ –ú–æ–∂–Ω–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å workers (N –≤–æ—Ä–∫–µ—Ä–æ–≤ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)
- ‚úÖ Retry –ª–æ–≥–∏–∫–∞ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö AI API
- ‚úÖ Priority queues (–≤–∞–∂–Ω—ã–µ –∑–∞–¥–∞—á–∏ –ø–µ—Ä–≤—ã–º–∏)
- ‚úÖ Dead Letter Queue (–∞–Ω–∞–ª–∏–∑ —Å–±–æ–µ–≤)

### 1.4. –ù–æ–≤–∞—è —Ñ–∏—á–∞: Text-Based Wireframe Generation

**–ß—Ç–æ –¥–µ–ª–∞–µ—Ç (–∞–∫—Ç—É–∞–ª—å–Ω–æ):**
```
User Story ‚Üí AI (Gemini/Groq/Perplexity) ‚Üí ASCII —Å—Ö–µ–º–∞ + Markdown –æ–ø–∏—Å–∞–Ω–∏–µ
```

- ASCII-–≤–∞–π—Ä—Ñ—Ä–µ–π–º (box drawing)
- Layout/Navigation/UI Elements –≤ Markdown
- –õ–µ–≥–∫–æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –∏ —Ö—Ä–∞–Ω–∏—Ç—å –≤ git, –Ω–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π

**Use cases:**
1. **Product Manager:** –ë—ã—Å—Ç—Ä–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –≤ —Ç–µ–∫—Å—Ç–µ
2. **Designer:** –°—Ç–∞—Ä—Ç–æ–≤–∞—è —Å—Ö–µ–º–∞ –±–µ–∑ –≥—Ä–∞—Ñ–∏–∫–∏
3. **Developer:** –ß—ë—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ UI/flows
4. **Stakeholder:** –ë—ã—Å—Ç—Ä—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –±–µ–∑ —Ç—è–∂—ë–ª—ã—Ö —Ñ–∞–π–ª–æ–≤

---

## 2. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–∏—Å—Ç–µ–º—ã

### 2.1. High-Level Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    CLIENT (Browser)                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ  ‚îÇ   React UI   ‚îÇ  ‚îÇ  WebSocket   ‚îÇ  ‚îÇ   Polling    ‚îÇ          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ HTTP/HTTPS       ‚îÇ WS/WSS           ‚îÇ HTTP
          ‚Üì                  ‚Üì                  ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    BACKEND (FastAPI)                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  REST API Endpoints:                                     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ POST /generate-map-async                              ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ POST /wireframes/generate                             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ GET  /job/{job_id}                                    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ WS   /ws/jobs/{job_id}                                ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ           ‚îÇ                                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Services:                                                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ rabbitmq_service.py  (Producer)                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ job_service.py       (Redis status tracking)          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ ai_service.py        (AI API calls)                    ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ
            ‚Üì publish()
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              CloudAMQP (RabbitMQ Cloud)                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Exchange: ai.tasks (type: topic)                         ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ       ‚îÇ                   ‚îÇ                  ‚îÇ                  ‚îÇ
‚îÇ       ‚îÇ routing_key:      ‚îÇ routing_key:     ‚îÇ routing_key:     ‚îÇ
‚îÇ       ‚îÇ ai.task.map.#     ‚îÇ ai.task.wf.#     ‚îÇ ai.task.bulk.#   ‚îÇ
‚îÇ       ‚Üì                   ‚Üì                  ‚Üì                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ  ‚îÇ   Queue:    ‚îÇ    ‚îÇ   Queue:    ‚îÇ    ‚îÇ   Queue:    ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ai.map.    ‚îÇ    ‚îÇ  ai.wireframe‚îÇ    ‚îÇ  ai.bulk.   ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  generation ‚îÇ    ‚îÇ  .generation ‚îÇ    ‚îÇ  improve    ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ             ‚îÇ    ‚îÇ             ‚îÇ    ‚îÇ             ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ durable   ‚îÇ    ‚îÇ ‚Ä¢ durable   ‚îÇ    ‚îÇ ‚Ä¢ durable   ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ priority  ‚îÇ    ‚îÇ ‚Ä¢ priority  ‚îÇ    ‚îÇ ‚Ä¢ TTL: 1h   ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ TTL: 1h   ‚îÇ    ‚îÇ ‚Ä¢ TTL: 1h   ‚îÇ    ‚îÇ             ‚îÇ        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ consume()        ‚îÇ consume()        ‚îÇ consume()
         ‚Üì                  ‚Üì                  ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      WORKERS (Consumers)                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  Map Worker     ‚îÇ  ‚îÇ Wireframe Worker ‚îÇ  ‚îÇ  Bulk Worker   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ   ‚îÇ  ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ  ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  1. Get message ‚îÇ  ‚îÇ  1. Get message  ‚îÇ  ‚îÇ  1. Get msgs   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  2. Update job  ‚îÇ  ‚îÇ  2. Update job   ‚îÇ  ‚îÇ  2. Process    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     status:     ‚îÇ  ‚îÇ     status:      ‚îÇ  ‚îÇ     parallel   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     processing  ‚îÇ  ‚îÇ     processing   ‚îÇ  ‚îÇ  3. Notify     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  3. Call AI     ‚îÇ  ‚îÇ  3. Get stories  ‚îÇ  ‚îÇ                ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     (Gemini/    ‚îÇ  ‚îÇ  4. Generate     ‚îÇ  ‚îÇ                ‚îÇ ‚îÇ
‚îÇ  ‚îÇ      Groq/      ‚îÇ  ‚îÇ     text prompt  ‚îÇ  ‚îÇ                ‚îÇ ‚îÇ
‚îÇ  ‚îÇ      Perplexity)‚îÇ  ‚îÇ  5. Call AI      ‚îÇ  ‚îÇ                ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  4. Save to DB  ‚îÇ  ‚îÇ     (ASCII/MD)   ‚îÇ  ‚îÇ                ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  5. Update job  ‚îÇ  ‚îÇ  6. Update job   ‚îÇ  ‚îÇ                ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     status:     ‚îÇ  ‚îÇ     status       ‚îÇ  ‚îÇ                ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     completed   ‚îÇ  ‚îÇ  7. Notify WS    ‚îÇ  ‚îÇ                ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  6. Notify WS   ‚îÇ  ‚îÇ                  ‚îÇ  ‚îÇ                ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ                  ‚îÇ  ‚îÇ                ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ                  ‚îÇ                       ‚îÇ
            ‚Üì                  ‚Üì                       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    EXTERNAL SERVICES                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                             ‚îÇ
‚îÇ  ‚îÇ   Gemini     ‚îÇ  ‚îÇ    Groq      ‚îÇ                             ‚îÇ
‚îÇ  ‚îÇ /Perplexity  ‚îÇ  ‚îÇ (fallback)   ‚îÇ                             ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ                  ‚îÇ
            ‚Üì                  ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    DATA LAYER                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                            ‚îÇ
‚îÇ  ‚îÇ  PostgreSQL  ‚îÇ  ‚îÇ    Redis     ‚îÇ                            ‚îÇ
‚îÇ  ‚îÇ  (Supabase)  ‚îÇ  ‚îÇ  (Job Status)‚îÇ                            ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ                            ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Projects  ‚îÇ  ‚îÇ  ‚Ä¢ job:{id}  ‚îÇ                            ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Stories   ‚îÇ  ‚îÇ  ‚Ä¢ TTL: 1h   ‚îÇ                            ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Activities‚îÇ  ‚îÇ              ‚îÇ                            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 2.2. Message Flow (–¥–µ—Ç–∞–ª—å–Ω–æ)

#### 2.2.1. User Story Map Generation Flow

```
[1] User clicks "Generate Map"
       ‚Üì
[2] Frontend: POST /generate-map-async
       {
         text: "–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –¥–æ—Å—Ç–∞–≤–∫–∏ –µ–¥—ã...",
         skip_enhancement: false,
         use_enhanced_text: true
       }
       ‚Üì
[3] Backend API (/api/projects.py):
       ‚Ä¢ Generate job_id = uuid4()
       ‚Ä¢ Create job in Redis:
         {
           job_id: "123-456-789",
           user_id: 42,
           status: "pending",
           created_at: "2025-12-01T10:00:00Z"
         }
       ‚Ä¢ Publish to RabbitMQ:
         exchange: "ai.tasks"
         routing_key: "ai.task.map.generation"
         message: {
           job_id: "123-456-789",
           user_id: 42,
           requirements_text: "...",
           use_enhancement: true
         }
       ‚Ä¢ Return 202 Accepted:
         {
           status: "accepted",
           job_id: "123-456-789",
           websocket_url: "/ws/jobs/123-456-789"
         }
       ‚Üì
[4] Frontend: Connect WebSocket
       ws = new WebSocket("/ws/jobs/123-456-789?token=...")

       ws.onmessage = (event) => {
         // Receive status updates
       }
       ‚Üì
[5] RabbitMQ: Route message to queue "ai.map.generation"
       ‚Üì
[6] Map Worker (workers/map_worker.py):
       ‚Ä¢ Consume message from queue
       ‚Ä¢ Update Redis: status = "processing"
       ‚Ä¢ Call enhance_requirements() if needed
       ‚Ä¢ Call generate_ai_map() ‚Üí Groq/OpenAI API
       ‚Ä¢ Parse JSON response
       ‚Ä¢ Save to PostgreSQL:
         - Create Project
         - Create Activities
         - Create Tasks
         - Create Stories
       ‚Ä¢ Update Redis: status = "completed", result = {project_id: 456}
       ‚Ä¢ ACK message to RabbitMQ
       ‚Üì
[7] WebSocket Server:
       ‚Ä¢ Poll Redis every 2 sec
       ‚Ä¢ Detect status change
       ‚Ä¢ Send to client:
         {
           type: "status_changed",
           status: "completed",
           result: {project_id: 456}
         }
       ‚Üì
[8] Frontend:
       ‚Ä¢ Receive WebSocket message
       ‚Ä¢ Fetch project: GET /project/456
       ‚Ä¢ Render StoryMap component
       ‚Ä¢ Show success notification
```

**–í—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞:**
```
0s    User clicks "Generate"
1s    202 Accepted, WebSocket connected
2s    Worker picks up message, status: "processing"
3-30s AI generation (Groq/OpenAI)
31s   Save to DB, status: "completed"
32s   WebSocket notification
33s   Frontend loads project
```

#### 2.2.2. Wireframe Generation Flow (Text-Based)

```
[1] User selects stories + clicks "Generate Wireframes"
       ‚Üì
[2] Frontend: POST /wireframes/generate
       {
         project_id: 456,
         story_ids: [1, 2, 3],
         style: "low-fidelity",
         platform: "web"
       }
       ‚Üì
[3] Backend API (/api/wireframes.py):
       ‚Ä¢ Validate project ownership
       ‚Ä¢ Validate stories exist
       ‚Ä¢ Generate job_id
       ‚Ä¢ Create job in Redis
       ‚Ä¢ Publish to RabbitMQ:
         routing_key: "ai.task.wireframe.generation"
       ‚Ä¢ Return 202 Accepted
       ‚Üì
[4] RabbitMQ: Route to "ai.wireframe.generation" queue
       ‚Üì
[5] Wireframe Worker (workers/wireframe_worker_text.py):
       ‚Ä¢ Consume message
       ‚Ä¢ Update status: "processing"

       FOR EACH story:
         [5.1] Load story from DB (with context: task, activity)

         [5.2] Build text wireframe prompt (style/platform-aware)

         [5.3] Call AI provider (Gemini/Groq/Perplexity) via generate_ai_response()
               ‚Üí –ø–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç —Å –±–ª–æ–∫–æ–º ```ascii``` + —Ä–∞–∑–¥–µ–ª—ã

         [5.4] Parse response:
               - ascii_wireframe
               - layout_description
               - ui_elements
               - navigation
               - notes

         [5.5] Update progress in Redis (ascii + markdown, –±–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π)

       [5.6] Update status: "completed"
       ‚Üì
[6] WebSocket notification to user
       ‚Üì
[7] Frontend renders ASCII/Markdown wireframe
```

### 2.3. RabbitMQ Exchange & Queue Topology

```
Exchange: ai.tasks (type: topic, durable: true)
‚îÇ
‚îú‚îÄ Binding: routing_key = "ai.task.map.#"
‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚ñ∫ Queue: ai.map.generation
‚îÇ      Properties:
‚îÇ      ‚Ä¢ durable: true (survives broker restart)
‚îÇ      ‚Ä¢ arguments:
‚îÇ        - x-message-ttl: 3600000 (1 hour)
‚îÇ        - x-max-priority: 10 (priority support)
‚îÇ        - x-dead-letter-exchange: "dlx.ai.tasks"
‚îÇ      ‚Ä¢ consumers: map_worker.py (1-N instances)
‚îÇ
‚îú‚îÄ Binding: routing_key = "ai.task.wireframe.#"
‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚ñ∫ Queue: ai.wireframe.generation
‚îÇ      Properties:
‚îÇ      ‚Ä¢ durable: true
‚îÇ      ‚Ä¢ arguments:
‚îÇ        - x-message-ttl: 3600000
‚îÇ        - x-max-priority: 10
‚îÇ        - x-dead-letter-exchange: "dlx.ai.tasks"
‚îÇ      ‚Ä¢ consumers: wireframe_worker_text.py (1-N instances)
‚îÇ
‚îî‚îÄ Binding: routing_key = "ai.task.bulk.#"
   ‚îÇ
   ‚îî‚îÄ‚ñ∫ Queue: ai.bulk.improve
       Properties:
       ‚Ä¢ durable: true
       ‚Ä¢ arguments:
         - x-message-ttl: 3600000
       ‚Ä¢ consumers: bulk_worker.py (optional, future)

Dead Letter Exchange: dlx.ai.tasks (type: fanout)
‚îÇ
‚îî‚îÄ‚ñ∫ Queue: ai.tasks.failed
    ‚Ä¢ Stores failed messages for analysis
    ‚Ä¢ Manual retry or debugging
```

**Routing Examples:**

| Message | Routing Key | Queue Destination |
|---------|-------------|-------------------|
| Map generation | `ai.task.map.generation` | `ai.map.generation` |
| Map generation (priority) | `ai.task.map.generation.priority` | `ai.map.generation` |
| Wireframe gen | `ai.task.wireframe.generation` | `ai.wireframe.generation` |
| Bulk improve | `ai.task.bulk.improve` | `ai.bulk.improve` |

### 2.4. Data Models

#### 2.4.1. Redis Job Schema

```python
# Key: job:{job_id}
# TTL: 3600 seconds (1 hour)
# Value: JSON

{
  "job_id": "uuid-string",
  "user_id": 123,
  "job_type": "ai_map_generation" | "wireframe_generation" | "bulk_improve",
  "status": "pending" | "processing" | "completed" | "failed",
  "created_at": "2025-12-01T10:00:00.000Z",
  "updated_at": "2025-12-01T10:05:00.000Z",
  "metadata": {
    // job-specific metadata
    "project_name": "Food Delivery App",
    "story_count": 3,
    "style": "low-fidelity",
    ...
  },
  "result": {
    // populated on completion
    "project_id": 456,
    "wireframes": [...]
  },
  "error": "Error message if failed",
  "progress": {
    // optional, for long-running jobs
    "current": 2,
    "total": 5,
    "message": "Processing story 2 of 5"
  }
}
```

#### 2.4.2. RabbitMQ Message Schema

**Map Generation Message:**
```json
{
  "job_id": "abc-123",
  "user_id": 42,
  "requirements_text": "–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è...",
  "use_enhancement": true,
  "created_at": "2025-12-01T10:00:00Z",
  "_metadata": {
    "message_id": "msg-456",
    "timestamp": "2025-12-01T10:00:00Z",
    "producer": "usm-backend"
  }
}
```

**Wireframe Generation Message:**
```json
{
  "job_id": "def-789",
  "user_id": 42,
  "project_id": 456,
  "story_ids": [1, 2, 3],
  "style": "low-fidelity",
  "platform": "web",
  "created_at": "2025-12-01T10:00:00Z",
  "_metadata": {
    "message_id": "msg-789",
    "timestamp": "2025-12-01T10:00:00Z",
    "producer": "usm-backend"
  }
}
```

---

## 3. –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

### 3.1. Development Environment

**–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã:**
```bash
# Python 3.9+
python --version
# Python 3.11.5

# pip
pip --version
# pip 23.3.1

# Node.js 18+
node --version
# v20.10.0

# npm
npm --version
# 10.2.3

# Git
git --version
# git version 2.42.0

# Docker (–¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ RabbitMQ)
docker --version
# Docker version 24.0.7

# Docker Compose
docker-compose --version
# docker-compose version 1.29.2
```

**–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã:**
```bash
# HTTPie (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è API)
brew install httpie

# jq (–¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ JSON)
brew install jq

# psql (PostgreSQL client)
brew install postgresql@15

# redis-cli
brew install redis
```

### 3.2. Cloud Accounts (FREE)

**1. CloudAMQP (RabbitMQ hosting)**
- URL: https://www.cloudamqp.com/
- –ü–ª–∞–Ω: Little Lemur (FREE)
- –õ–∏–º–∏—Ç—ã:
  - 1 million messages/month
  - 5 concurrent connections
  - 25 queues max
  - Shared instance

**–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è:**
```
1. –ü–µ—Ä–µ–π—Ç–∏ –Ω–∞ cloudamqp.com
2. Sign Up (GitHub/Google/Email)
3. Dashboard ‚Üí Create New Instance
4. Name: usm-rabbitmq-dev
5. Plan: Little Lemur (FREE)
6. Region: –≤—ã–±—Ä–∞—Ç—å –±–ª–∏–∂–∞–π—à–∏–π (eu-north-1 –¥–ª—è –†–æ—Å—Å–∏–∏)
7. Create instance
8. –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å CLOUDAMQP_URL:
   amqps://username:password@host.cloudamqp.com/vhost
```

**2. AI API (–¥–ª—è text wireframes)**
- –ö–ª—é—á–∏: GEMINI_API_KEY / GROQ_API_KEY / PERPLEXITY_API_KEY
- –ú–æ–¥–µ–ª–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ; –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ —Ç—Ä–µ–±—É—é—Ç—Å—è

**3. Supabase (PostgreSQL) - —É–∂–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è**
- URL: https://supabase.com/
- –ü–ª–∞–Ω: Free tier
- –õ–∏–º–∏—Ç—ã:
  - 500 MB database
  - 2 GB bandwidth/month
  - Unlimited API requests

**5. Upstash Redis - —É–∂–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è**
- URL: https://upstash.com/
- –ü–ª–∞–Ω: Free tier
- –õ–∏–º–∏—Ç—ã:
  - 10K requests/day
  - 256 MB storage

### 3.3. –°–∏—Å—Ç–µ–º–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

**–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ:**
- CPU: 2 cores
- RAM: 4 GB
- Disk: 5 GB free space

**–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ:**
- CPU: 4+ cores
- RAM: 8+ GB
- Disk: 10+ GB free space
- SSD –¥–ª—è –ë–î

### 3.4. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–∫—É—â–µ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è

–°–æ–∑–¥–∞–π—Ç–µ —Å–∫—Ä–∏–ø—Ç `check-environment.sh`:

```bash
#!/bin/bash

echo "üîç Checking environment..."

# Colors
GREEN='\033[0;32m'
RED='\033[0;31m'
NC='\033[0m' # No Color

check_command() {
  if command -v $1 &> /dev/null; then
    echo -e "${GREEN}‚úì${NC} $1 is installed"
  else
    echo -e "${RED}‚úó${NC} $1 is NOT installed"
  fi
}

# Check commands
echo ""
echo "=== Required Tools ==="
check_command python3
check_command pip3
check_command node
check_command npm
check_command git

echo ""
echo "=== Optional Tools ==="
check_command docker
check_command docker-compose
check_command http
check_command jq

# Check Python version
echo ""
echo "=== Python Version ==="
python3 --version

# Check Node version
echo ""
echo "=== Node Version ==="
node --version

# Check environment variables
echo ""
echo "=== Environment Variables ==="

check_env() {
  if [ -z "${!1}" ]; then
    echo -e "${RED}‚úó${NC} $1 is NOT set"
  else
    echo -e "${GREEN}‚úì${NC} $1 is set"
  fi
}

check_env "DATABASE_URL"
check_env "REDIS_URL"
check_env "GEMINI_API_KEY"
check_env "GROQ_API_KEY"
check_env "PERPLEXITY_API_KEY"

echo ""
echo "=== New Required Variables ==="
check_env "RABBITMQ_URL"

echo ""
echo "‚úÖ Environment check complete!"
```

–ó–∞–ø—É—Å–∫:
```bash
chmod +x check-environment.sh
./check-environment.sh
```

---

## 4. Phase 1: RabbitMQ Setup

### 4.1. Option A: CloudAMQP (Production & Development)

#### 4.1.1. –°–æ–∑–¥–∞–Ω–∏–µ instance

**Step-by-step:**

1. **–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –∏ –≤—Ö–æ–¥:**
   ```
   https://customer.cloudamqp.com/login
   Email: your-email@example.com
   Password: ********
   ```

2. **–°–æ–∑–¥–∞–Ω–∏–µ instance:**
   ```
   Dashboard ‚Üí Create New Instance

   Name: usm-rabbitmq-dev
   Plan: Little Lemur (FREE)
   Region: EU-North-1-A (Stockholm) - –¥–ª—è –ï–≤—Ä–æ–ø—ã/–†–æ—Å—Å–∏–∏
          –∏–ª–∏ US-East-1 (Virginia) - –¥–ª—è –°–®–ê

   Tags: development, usm-project

   [Create instance]
   ```

3. **–ü–æ–ª—É—á–µ–Ω–∏–µ credentials:**
   ```
   Click –Ω–∞ instance ‚Üí Details

   –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å:
   ‚Ä¢ URL: amqps://vrcptkqu:***@hawk-01.rmq.cloudamqp.com/vrcptkqu
   ‚Ä¢ Host: hawk-01.rmq.cloudamqp.com
   ‚Ä¢ Virtual host: vrcptkqu
   ‚Ä¢ Username: vrcptkqu
   ‚Ä¢ Password: ***
   ```

4. **Management UI:**
   ```
   Click –Ω–∞ instance ‚Üí RabbitMQ Manager

   –û—Ç–∫—Ä–æ–µ—Ç—Å—è: https://hawk-01.rmq.cloudamqp.com/#/

   –ó–¥–µ—Å—å –º–æ–∂–Ω–æ:
   ‚Ä¢ –°–º–æ—Ç—Ä–µ—Ç—å –æ—á–µ—Ä–µ–¥–∏
   ‚Ä¢ –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è
   ‚Ä¢ –°–æ–∑–¥–∞–≤–∞—Ç—å exchanges –≤—Ä—É—á–Ω—É—é
   ‚Ä¢ –ü—Ä–æ—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å connections
   ```

#### 4.1.2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ .env —Ñ–∞–π–ª–∞

–°–æ–∑–¥–∞–π—Ç–µ `.env` –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞:

```bash
# backend/.env

# ========================================
# RabbitMQ Configuration (CloudAMQP)
# ========================================
RABBITMQ_ENABLED=true
CLOUDAMQP_URL=amqps://username:password@host.cloudamqp.com/vhost

# Alternative –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:
# RABBITMQ_URL=amqp://admin:admin123@localhost:5672/

# ========================================
# ========================================
# AI API Keys (text wireframes)
# ========================================
GEMINI_API_KEY=AIza...
GROQ_API_KEY=gsk-...
PERPLEXITY_API_KEY=pplx-...

# ========================================
# Database (existing)
# ========================================
DATABASE_URL=postgresql://user:pass@host:5432/db

# ========================================
# Redis (existing)
# ========================================
REDIS_URL=redis://localhost:6379/0

# ========================================
# JWT (existing)
# ========================================
JWT_SECRET_KEY=your-super-secret-key-min-32-chars
JWT_ALGORITHM=HS256
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=30
JWT_REFRESH_TOKEN_EXPIRE_DAYS=7

# ========================================
# CORS (existing)
# ========================================
ALLOWED_ORIGINS=http://localhost:5173,http://127.0.0.1:5173

# ========================================
# Logging
# ========================================
LOG_LEVEL=INFO

# ========================================
# Environment
# ========================================
ENVIRONMENT=development
```

**–í–∞–∂–Ω–æ:** –î–æ–±–∞–≤—å—Ç–µ `.env` –≤ `.gitignore`:

```bash
# .gitignore
.env
.env.local
.env.production
*.env
```

#### 4.1.3. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è

–°–æ–∑–¥–∞–π—Ç–µ —Å–∫—Ä–∏–ø—Ç `test-rabbitmq-connection.py`:

```python
"""
–¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ RabbitMQ (CloudAMQP –∏–ª–∏ –ª–æ–∫–∞–ª—å–Ω–æ–º—É)
"""
import asyncio
import os
from dotenv import load_dotenv
import aio_pika

load_dotenv()

async def test_connection():
    rabbitmq_url = os.getenv("CLOUDAMQP_URL") or os.getenv("RABBITMQ_URL")

    if not rabbitmq_url:
        print("‚ùå RABBITMQ_URL or CLOUDAMQP_URL not set in .env")
        return

    print(f"üîå Connecting to RabbitMQ...")
    print(f"   URL: {rabbitmq_url[:20]}...{rabbitmq_url[-20:]}")

    try:
        # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
        connection = await aio_pika.connect_robust(
            rabbitmq_url,
            timeout=30
        )
        print("‚úÖ Connection established!")

        # –°–æ–∑–¥–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–∞
        channel = await connection.channel()
        print("‚úÖ Channel created!")

        # –°–æ–∑–¥–∞–Ω–∏–µ test exchange
        exchange = await channel.declare_exchange(
            "test.exchange",
            aio_pika.ExchangeType.TOPIC,
            durable=False,
            auto_delete=True
        )
        print("‚úÖ Test exchange created!")

        # –°–æ–∑–¥–∞–Ω–∏–µ test queue
        queue = await channel.declare_queue(
            "test.queue",
            durable=False,
            auto_delete=True
        )
        print("‚úÖ Test queue created!")

        # Bind
        await queue.bind(exchange, routing_key="test.#")
        print("‚úÖ Queue bound to exchange!")

        # Publish test message
        message = aio_pika.Message(
            body=b'{"test": "message"}',
            content_type="application/json"
        )
        await exchange.publish(message, routing_key="test.message")
        print("‚úÖ Test message published!")

        # Consume
        async with queue.iterator() as queue_iter:
            async for msg in queue_iter:
                async with msg.process():
                    print(f"‚úÖ Test message received: {msg.body.decode()}")
                    break

        # Cleanup
        await connection.close()
        print("‚úÖ Connection closed!")

        print("\nüéâ RabbitMQ connection test PASSED!")

    except Exception as e:
        print(f"\n‚ùå RabbitMQ connection test FAILED!")
        print(f"   Error: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(test_connection())
```

–ó–∞–ø—É—Å–∫:
```bash
cd backend
pip install aio-pika python-dotenv
python test-rabbitmq-connection.py
```

**–û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥:**
```
üîå Connecting to RabbitMQ...
   URL: amqps://vrcptkqu:***...oudamqp.com/vrcptkqu
‚úÖ Connection established!
‚úÖ Channel created!
‚úÖ Test exchange created!
‚úÖ Test queue created!
‚úÖ Queue bound to exchange!
‚úÖ Test message published!
‚úÖ Test message received: {"test": "message"}
‚úÖ Connection closed!

üéâ RabbitMQ connection test PASSED!
```

### 4.2. Option B: Local Docker RabbitMQ (Development Only)

#### 4.2.1. Docker Compose Setup

–°–æ–∑–¥–∞–π—Ç–µ `docker-compose.rabbitmq.yml`:

```yaml
version: '3.8'

services:
  rabbitmq:
    image: rabbitmq:3.12-management-alpine
    container_name: usm-rabbitmq
    hostname: usm-rabbitmq

    ports:
      - "5672:5672"    # AMQP protocol
      - "15672:15672"  # Management UI

    environment:
      # Default credentials
      RABBITMQ_DEFAULT_USER: admin
      RABBITMQ_DEFAULT_PASS: admin123

      # Virtual host
      RABBITMQ_DEFAULT_VHOST: /

      # Logging
      RABBITMQ_LOG_LEVEL: info

      # Memory limits
      RABBITMQ_VM_MEMORY_HIGH_WATERMARK: 512MB

    volumes:
      # Persistent data
      - rabbitmq-data:/var/lib/rabbitmq

      # Configuration (optional)
      - ./rabbitmq-config/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf:ro
      - ./rabbitmq-config/definitions.json:/etc/rabbitmq/definitions.json:ro

    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "-q", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s

    restart: unless-stopped

    networks:
      - usm-network

volumes:
  rabbitmq-data:
    driver: local

networks:
  usm-network:
    driver: bridge
```

#### 4.2.2. RabbitMQ Configuration File (optional)

–°–æ–∑–¥–∞–π—Ç–µ `rabbitmq-config/rabbitmq.conf`:

```ini
# RabbitMQ Configuration

# Network
listeners.tcp.default = 5672
management.tcp.port = 15672

# Logging
log.console = true
log.console.level = info
log.file = false

# Memory
vm_memory_high_watermark.relative = 0.6
vm_memory_high_watermark_paging_ratio = 0.75

# Disk
disk_free_limit.relative = 1.0

# Heartbeat
heartbeat = 60

# Default user
default_user = admin
default_pass = admin123
default_vhost = /

# Management plugin
management.load_definitions = /etc/rabbitmq/definitions.json
```

#### 4.2.3. RabbitMQ Definitions (Pre-create queues)

–°–æ–∑–¥–∞–π—Ç–µ `rabbitmq-config/definitions.json`:

```json
{
  "rabbit_version": "3.12",
  "users": [
    {
      "name": "admin",
      "password_hash": "JThRmHSgx0hb3n4Qp1h8JhH2gV8LhH6b",
      "hashing_algorithm": "rabbit_password_hashing_sha256",
      "tags": "administrator"
    }
  ],
  "vhosts": [
    {
      "name": "/"
    }
  ],
  "permissions": [
    {
      "user": "admin",
      "vhost": "/",
      "configure": ".*",
      "write": ".*",
      "read": ".*"
    }
  ],
  "topic_permissions": [],
  "parameters": [],
  "global_parameters": [
    {
      "name": "cluster_name",
      "value": "usm-rabbitmq-cluster"
    }
  ],
  "policies": [],
  "queues": [
    {
      "name": "ai.map.generation",
      "vhost": "/",
      "durable": true,
      "auto_delete": false,
      "arguments": {
        "x-message-ttl": 3600000,
        "x-max-priority": 10
      }
    },
    {
      "name": "ai.wireframe.generation",
      "vhost": "/",
      "durable": true,
      "auto_delete": false,
      "arguments": {
        "x-message-ttl": 3600000,
        "x-max-priority": 10
      }
    },
    {
      "name": "ai.bulk.improve",
      "vhost": "/",
      "durable": true,
      "auto_delete": false,
      "arguments": {
        "x-message-ttl": 3600000
      }
    }
  ],
  "exchanges": [
    {
      "name": "ai.tasks",
      "vhost": "/",
      "type": "topic",
      "durable": true,
      "auto_delete": false,
      "internal": false,
      "arguments": {}
    },
    {
      "name": "dlx.ai.tasks",
      "vhost": "/",
      "type": "fanout",
      "durable": true,
      "auto_delete": false,
      "internal": false,
      "arguments": {}
    }
  ],
  "bindings": [
    {
      "source": "ai.tasks",
      "vhost": "/",
      "destination": "ai.map.generation",
      "destination_type": "queue",
      "routing_key": "ai.task.map.#",
      "arguments": {}
    },
    {
      "source": "ai.tasks",
      "vhost": "/",
      "destination": "ai.wireframe.generation",
      "destination_type": "queue",
      "routing_key": "ai.task.wireframe.#",
      "arguments": {}
    },
    {
      "source": "ai.tasks",
      "vhost": "/",
      "destination": "ai.bulk.improve",
      "destination_type": "queue",
      "routing_key": "ai.task.bulk.#",
      "arguments": {}
    }
  ]
}
```

#### 4.2.4. –ó–∞–ø—É—Å–∫ RabbitMQ

```bash
# –°–æ–∑–¥–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
mkdir -p rabbitmq-config

# –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã (—Å–º. –≤—ã—à–µ)

# –ó–∞–ø—É—Å—Ç–∏—Ç—å RabbitMQ
docker-compose -f docker-compose.rabbitmq.yml up -d

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ª–æ–≥–∏
docker-compose -f docker-compose.rabbitmq.yml logs -f rabbitmq

# –û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥:
# rabbitmq_1  | 2025-12-01 10:00:00.000 [info] <0.222.0> Server startup complete; 3 plugins started.
# rabbitmq_1  |  * rabbitmq_management
# rabbitmq_1  |  * rabbitmq_management_agent
# rabbitmq_1  |  * rabbitmq_web_dispatch
```

**–ü—Ä–æ–≤–µ—Ä–∫–∞:**
```bash
# Health check
docker exec usm-rabbitmq rabbitmq-diagnostics ping
# Output: Ping succeeded

# Check queues
docker exec usm-rabbitmq rabbitmqctl list_queues
# Output:
# Timeout: 60.0 seconds ...
# Listing queues for vhost / ...
# name	messages
# ai.map.generation	0
# ai.wireframe.generation	0
# ai.bulk.improve	0
```

**Management UI:**
```
http://localhost:15672/

Username: admin
Password: admin123
```

**–°–∫—Ä–∏–Ω—à–æ—Ç—ã Management UI:**

1. **Overview:**
   - Total queued messages
   - Message rates (publish/deliver)
   - Connection count
   - Channel count

2. **Queues tab:**
   - –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –æ—á–µ—Ä–µ–¥–µ–π
   - Messages ready/unacked
   - Publish/deliver rates
   - Consumers count

3. **Exchanges tab:**
   - ai.tasks (topic)
   - dlx.ai.tasks (fanout)

#### 4.2.5. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ .env –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ RabbitMQ

```bash
# backend/.env

RABBITMQ_ENABLED=true
RABBITMQ_URL=amqp://admin:admin123@localhost:5672/

# –ö–æ–º–º–µ–Ω—Ç–∏—Ä—É–µ–º CloudAMQP URL
# CLOUDAMQP_URL=amqps://...
```

### 4.3. Troubleshooting RabbitMQ Connection

#### Problem 1: Connection timeout

**–°–∏–º–ø—Ç–æ–º—ã:**
```
asyncio.exceptions.TimeoutError: Connection timeout
```

**–†–µ—à–µ–Ω–∏—è:**
```bash
# 1. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Ö–æ—Å—Ç–∞
ping hawk-01.rmq.cloudamqp.com

# 2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å firewall
telnet hawk-01.rmq.cloudamqp.com 5672

# 3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å SSL/TLS (–¥–ª—è CloudAMQP)
openssl s_client -connect hawk-01.rmq.cloudamqp.com:5671

# 4. –£–≤–µ–ª–∏—á–∏—Ç—å timeout –≤ –∫–æ–¥–µ
connection = await aio_pika.connect_robust(
    rabbitmq_url,
    timeout=60  # —É–≤–µ–ª–∏—á–∏—Ç—å —Å 30 –¥–æ 60 —Å–µ–∫—É–Ω–¥
)
```

#### Problem 2: Authentication failed

**–°–∏–º–ø—Ç–æ–º—ã:**
```
aio_pika.exceptions.ProbableAuthenticationError: Authentication failed
```

**–†–µ—à–µ–Ω–∏—è:**
```bash
# 1. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å credentials –≤ .env
echo $CLOUDAMQP_URL

# 2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å special characters –≤ –ø–∞—Ä–æ–ª–µ
# –ï—Å–ª–∏ –ø–∞—Ä–æ–ª—å —Å–æ–¥–µ—Ä–∂–∏—Ç @, #, % –∏ —Ç.–¥., –Ω—É–∂–Ω–æ URL-encode
# –ü—Ä–∏–º–µ—Ä: password "p@ss#123" ‚Üí "p%40ss%23123"

# 3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å username/password –≤ CloudAMQP UI
# Dashboard ‚Üí Instance ‚Üí Details

# 4. –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å reconnect —á–µ—Ä–µ–∑ Management UI
# Dashboard ‚Üí Instance ‚Üí RabbitMQ Manager ‚Üí Test connection
```

#### Problem 3: Channel closed unexpectedly

**–°–∏–º–ø—Ç–æ–º—ã:**
```
aio_pika.exceptions.ChannelClosed: Channel closed by server
```

**–†–µ—à–µ–Ω–∏—è:**
```python
# 1. –î–æ–±–∞–≤–∏—Ç—å error handling
try:
    await channel.declare_queue(...)
except aio_pika.exceptions.ChannelClosed as e:
    logger.error(f"Channel closed: {e}")
    # Recreate channel
    channel = await connection.channel()

# 2. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å connect_robust –¥–ª—è auto-reconnect
connection = await aio_pika.connect_robust(
    rabbitmq_url,
    timeout=30
)
# connect_robust –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è –ø—Ä–∏ –æ–±—Ä—ã–≤–∞—Ö

# 3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å limits CloudAMQP
# Little Lemur: max 5 connections
# –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –Ω–µ –ø—Ä–µ–≤—ã—à–∞–µ—Ç–µ –ª–∏–º–∏—Ç
```

#### Problem 4: Queue already exists with different arguments

**–°–∏–º–ø—Ç–æ–º—ã:**
```
PRECONDITION_FAILED - inequivalent arg 'x-message-ttl' for queue 'ai.map.generation'
```

**–†–µ—à–µ–Ω–∏—è:**
```python
# –í–∞—Ä–∏–∞–Ω—Ç 1: –£–¥–∞–ª–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –æ—á–µ—Ä–µ–¥—å –≤—Ä—É—á–Ω—É—é
# RabbitMQ Manager ‚Üí Queues ‚Üí Delete queue

# –í–∞—Ä–∏–∞–Ω—Ç 2: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å passive=True –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
queue = await channel.declare_queue(
    "ai.map.generation",
    passive=True  # –ù–µ —Å–æ–∑–¥–∞–µ—Ç, —Ç–æ–ª—å–∫–æ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ
)

# –í–∞—Ä–∏–∞–Ω—Ç 3: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥—Ä—É–≥–æ–µ –∏–º—è –æ—á–µ—Ä–µ–¥–∏
queue = await channel.declare_queue(
    "ai.map.generation.v2",  # –Ω–æ–≤–æ–µ –∏–º—è
    durable=True,
    arguments={"x-message-ttl": 3600000}
)
```

---

## 5. Phase 2: Backend Infrastructure

### 5.1. Python Dependencies

#### 5.1.1. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ requirements.txt

–û–±–Ω–æ–≤–∏—Ç–µ `backend/requirements.txt`:

```txt
# ========================================
# Web Framework
# ========================================
fastapi==0.109.0
uvicorn[standard]==0.27.0
python-multipart==0.0.6

# ========================================
# Database
# ========================================
sqlalchemy==2.0.25
alembic==1.13.1
psycopg2-binary==2.9.9

# ========================================
# Authentication
# ========================================
python-jose[cryptography]==3.3.0
passlib[bcrypt]==1.7.4
python-dotenv==1.0.0

# ========================================
# Rate Limiting & CORS
# ========================================
slowapi==0.1.9
python-cors==1.0.0

# ========================================
# AI APIs
# ========================================
openai==1.10.0
anthropic==0.10.0  # optional, for Claude

# ========================================
# RabbitMQ (NEW)
# ========================================
aio-pika==9.4.0
aiormq==6.8.0

# ========================================
# Redis
# ========================================
redis==5.0.1
aioredis==2.0.1  # –¥–ª—è async operations

# ========================================
# WebSocket
# ========================================
websockets==12.0

# ========================================
# Image Processing (–¥–ª—è wireframes)
# ========================================
Pillow==10.2.0
cloudinary==1.38.0

# ========================================
# Utilities
# ========================================
pydantic==2.5.3
pydantic-settings==2.1.0
scikit-learn==1.4.0  # –¥–ª—è TF-IDF analysis
numpy==1.26.3

# ========================================
# Testing
# ========================================
pytest==7.4.4
pytest-asyncio==0.23.3
httpx==0.26.0  # –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è FastAPI

# ========================================
# Monitoring (optional)
# ========================================
sentry-sdk==1.39.2
prometheus-client==0.19.0

# ========================================
# Development
# ========================================
black==24.1.0
flake8==7.0.0
isort==5.13.2
```

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞:**
```bash
cd backend

# –°–æ–∑–¥–∞—Ç—å –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ (–µ—Å–ª–∏ –µ—â–µ –Ω–µ —Å–æ–∑–¥–∞–Ω–æ)
python -m venv venv

# –ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å
source venv/bin/activate  # macOS/Linux
# –∏–ª–∏
venv\Scripts\activate  # Windows

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
pip install -r requirements.txt

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏
pip list | grep aio-pika
# aio-pika             9.4.0

pip list | grep cloudinary
# cloudinary           1.38.0
```

#### 5.1.2. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏

–°–æ–∑–¥–∞–π—Ç–µ `check-dependencies.py`:

```python
"""
–ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
"""
import sys

def check_import(module_name, import_path=None):
    try:
        if import_path:
            exec(f"from {module_name} import {import_path}")
        else:
            __import__(module_name)
        print(f"‚úÖ {module_name}")
        return True
    except ImportError as e:
        print(f"‚ùå {module_name}: {e}")
        return False

print("üîç Checking dependencies...\n")

# Core
check_import("fastapi")
check_import("uvicorn")
check_import("pydantic")

# Database
check_import("sqlalchemy")
check_import("alembic")
check_import("psycopg2")

# Auth
check_import("jose", "jwt")
check_import("passlib")

# RabbitMQ (NEW)
check_import("aio_pika")
check_import("aiormq")

# Redis
check_import("redis")

# Image (NEW)
check_import("PIL", "Image")
check_import("cloudinary")

# AI
check_import("openai")

# WebSocket
check_import("websockets")

# Testing
check_import("pytest")

print("\n‚úÖ All dependencies OK!")
```

–ó–∞–ø—É—Å–∫:
```bash
python check-dependencies.py
```

### 5.2. Configuration Updates

#### 5.2.1. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ config.py

–û–±–Ω–æ–≤–∏—Ç–µ `backend/config.py`:

```python
"""
–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π —á–µ—Ä–µ–∑ Pydantic Settings
"""
import os
from pathlib import Path
from typing import List, Optional
import logging

logger = logging.getLogger(__name__)


class Settings:
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""

    def __init__(self):
        # ==========================================
        # API Keys (existing)
        # ==========================================
        self.GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "")
        self.GROQ_API_KEY = os.getenv("GROQ_API_KEY", "")
        self.PERPLEXITY_API_KEY = os.getenv("PERPLEXITY_API_KEY", "")
        self.API_PROVIDER = os.getenv("API_PROVIDER", "")
        self.API_MODEL = os.getenv("API_MODEL", "")
        self.API_TEMPERATURE = float(os.getenv("API_TEMPERATURE", "0.7"))

        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –¥–ª—è fallback (—Ç–µ–∫—Å—Ç–æ–≤—ã–µ)
        self.AI_PROVIDER_PRIORITY = [
            p.strip() for p in os.getenv("AI_PROVIDER_PRIORITY", "gemini,groq,perplexity").split(",")
            if p.strip()
        ]

        # Two-Stage AI Processing
        self.ENHANCEMENT_MODEL = os.getenv("ENHANCEMENT_MODEL", "")

        # ==========================================
        # Database (existing)
        # ==========================================
        self.DATABASE_URL = os.getenv("DATABASE_URL", "sqlite:///./usm.db")

        # ==========================================
        # Redis (existing)
        # ==========================================
        self.REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6379/0")

        # ==========================================
        # JWT (existing)
        # ==========================================
        self.JWT_SECRET_KEY = os.getenv("JWT_SECRET_KEY", "your-secret-key-change-in-production")
        self.JWT_ALGORITHM = os.getenv("JWT_ALGORITHM", "HS256")
        self.JWT_ACCESS_TOKEN_EXPIRE_MINUTES = int(os.getenv("JWT_ACCESS_TOKEN_EXPIRE_MINUTES", "30"))
        self.JWT_REFRESH_TOKEN_EXPIRE_DAYS = int(os.getenv("JWT_REFRESH_TOKEN_EXPIRE_DAYS", "7"))

        # ==========================================
        # CORS (existing)
        # ==========================================
        self.ALLOWED_ORIGINS = os.getenv(
            "ALLOWED_ORIGINS",
            "http://localhost:5173,http://127.0.0.1:5173"
        )

        # ==========================================
        # RabbitMQ Configuration
        # ==========================================
        self.RABBITMQ_ENABLED = os.getenv("RABBITMQ_ENABLED", "false").lower() == "true"

        # CloudAMQP URL (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç) –∏–ª–∏ –ª–æ–∫–∞–ª—å–Ω—ã–π RabbitMQ
        self.RABBITMQ_URL = os.getenv(
            "CLOUDAMQP_URL",
            os.getenv("RABBITMQ_URL", "amqp://admin:admin123@localhost:5672/")
        )

        # RabbitMQ Queues
        self.QUEUE_AI_MAP_GENERATION = "ai.map.generation"
        self.QUEUE_AI_WIREFRAME_GENERATION = "ai.wireframe.generation"
        self.QUEUE_AI_BULK_IMPROVE = "ai.bulk.improve"

        # RabbitMQ Exchange
        self.EXCHANGE_AI_TASKS = "ai.tasks"
        self.EXCHANGE_DLX = "dlx.ai.tasks"

        # Queue Settings
        self.QUEUE_DURABLE = True
        self.MESSAGE_TTL = 3600000  # 1 hour in milliseconds
        self.PREFETCH_COUNT = 1  # Process one message at a time per worker

        # Connection Settings
        self.RABBITMQ_CONNECTION_TIMEOUT = 30  # seconds
        self.RABBITMQ_HEARTBEAT = 60  # seconds

        # ==========================================
        # Wireframe Generation Settings (text)
        # ==========================================
        self.WIREFRAME_MAX_STORIES = int(os.getenv("WIREFRAME_MAX_STORIES", "10"))

        # ==========================================
        # Logging (existing)
        # ==========================================
        self.LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO")

        # ==========================================
        # Sentry (existing)
        # ==========================================
        self.SENTRY_DSN = os.getenv("SENTRY_DSN", "")
        self.ENVIRONMENT = os.getenv("ENVIRONMENT", "development")

        # ==========================================
        # Worker Settings (NEW)
        # ==========================================
        self.WORKER_CONCURRENCY = int(os.getenv("WORKER_CONCURRENCY", "1"))
        self.WORKER_MAX_RETRIES = int(os.getenv("WORKER_MAX_RETRIES", "3"))
        self.WORKER_RETRY_DELAY = int(os.getenv("WORKER_RETRY_DELAY", "5"))  # seconds

        # Auto-setup
        self._set_api_provider()
        self._set_default_model()
        self._validate_settings()

    def _set_api_provider(self):
        """–ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ API –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –ø–æ –∫–ª—é—á—É"""
        if self.API_PROVIDER:
            return

        for provider in self.AI_PROVIDER_PRIORITY:
            if provider == "gemini" and self.GEMINI_API_KEY:
                self.API_PROVIDER = "gemini"
                return
            elif provider == "groq" and self.GROQ_API_KEY:
                self.API_PROVIDER = "groq"
                return
            elif provider == "perplexity" and self.PERPLEXITY_API_KEY:
                self.API_PROVIDER = "perplexity"
                return

        # Fallback: –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ —Ñ–æ—Ä–º–∞—Ç—É –∫–ª—é—á–∞
        api_key = self.get_api_key()
        if api_key:
            if api_key.startswith("AIza"):
                self.API_PROVIDER = "gemini"
            elif api_key.startswith("gsk_"):
                self.API_PROVIDER = "groq"
            elif api_key.startswith("pplx-"):
                self.API_PROVIDER = "perplexity"

    def _set_default_model(self):
        """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"""
        if self.API_MODEL:
            return

        if self.API_PROVIDER == "gemini":
            self.API_MODEL = "gemini-2.0-flash-exp"
        elif self.API_PROVIDER == "groq":
            self.API_MODEL = "llama-3.3-70b-versatile"
        elif self.API_PROVIDER == "perplexity":
            self.API_MODEL = "sonar"

    def _validate_settings(self):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ"""
        errors = []
        warnings = []

        # JWT Secret
        if self.ENVIRONMENT == "production":
            if self.JWT_SECRET_KEY == "your-secret-key-change-in-production":
                errors.append("JWT_SECRET_KEY must be changed in production!")

        if len(self.JWT_SECRET_KEY) < 32:
            warnings.append("JWT_SECRET_KEY should be at least 32 characters long")

        # Database
        if self.is_sqlite() and self.ENVIRONMENT == "production":
            warnings.append("SQLite is not recommended for production. Use PostgreSQL.")

        # AI Provider
        available_providers = self.get_available_providers()
        if not available_providers:
            warnings.append("No AI API keys configured. AI functions will be unavailable.")
        else:
            logger.info(f"‚úÖ AI providers available: {', '.join(available_providers)}")

        # RabbitMQ (NEW)
        if self.RABBITMQ_ENABLED:
            if not self.RABBITMQ_URL:
                errors.append("RABBITMQ_ENABLED=true but RABBITMQ_URL not set")
            else:
                logger.info(f"‚úÖ RabbitMQ enabled: {self._mask_url(self.RABBITMQ_URL)}")

        else:
            logger.info("‚ÑπÔ∏è RabbitMQ disabled - using synchronous processing")

        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ—à–∏–±–æ–∫ –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
        if errors:
            for error in errors:
                logger.error(f"‚ùå CONFIG ERROR: {error}")
            raise ValueError(f"Configuration errors: {errors}")

        if warnings:
            for warning in warnings:
                logger.warning(f"‚ö†Ô∏è CONFIG WARNING: {warning}")

    def get_api_key(self) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã–π API –∫–ª—é—á"""
        for provider in self.AI_PROVIDER_PRIORITY:
            if provider == "gemini" and self.GEMINI_API_KEY:
                return self.GEMINI_API_KEY
            elif provider == "groq" and self.GROQ_API_KEY:
                return self.GROQ_API_KEY
            elif provider == "perplexity" and self.PERPLEXITY_API_KEY:
                return self.PERPLEXITY_API_KEY
        return self.GEMINI_API_KEY or self.GROQ_API_KEY or self.PERPLEXITY_API_KEY

    def get_api_key_for_provider(self, provider: str) -> Optional[str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç API –∫–ª—é—á –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞"""
        if provider == "gemini":
            return self.GEMINI_API_KEY
        elif provider == "groq":
            return self.GROQ_API_KEY
        elif provider == "perplexity":
            return self.PERPLEXITY_API_KEY
        return None

    def get_available_providers(self) -> List[str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –≤ –ø–æ—Ä—è–¥–∫–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞"""
        available = []
        for provider in self.AI_PROVIDER_PRIORITY:
            if self.get_api_key_for_provider(provider):
                available.append(provider)
        return available

    def get_enhancement_model(self) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–æ–¥–µ–ª—å –¥–ª—è Stage 1 (—É–ª—É—á—à–µ–Ω–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π)"""
        return self.ENHANCEMENT_MODEL or self.API_MODEL

    def get_allowed_origins_list(self) -> List[str]:
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç ALLOWED_ORIGINS –≤ —Å–ø–∏—Å–æ–∫"""
        return [origin.strip() for origin in self.ALLOWED_ORIGINS.split(",")]

    def is_sqlite(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–∏ SQLite"""
        return self.DATABASE_URL.startswith("sqlite")


# Singleton instance
settings = Settings()
```

**–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:**

```bash
cd backend
python -c "from config import settings; print('Config loaded successfully!')"
```

**–û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥:**
```
‚úÖ AI providers available: gemini, groq, perplexity
‚úÖ RabbitMQ enabled: amqps://vrcptkqu:***@hawk-01.rmq.cloudamqp.com/vrcptkqu
Config loaded successfully!
```

### 5.3. RabbitMQ Service Layer

#### 5.3.1. –°–æ–∑–¥–∞–Ω–∏–µ rabbitmq_service.py

–°–æ–∑–¥–∞–π—Ç–µ `backend/services/rabbitmq_service.py`:

```python
"""
RabbitMQ service –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è–º–∏ –∏ –æ—á–µ—Ä–µ–¥—è–º–∏

–û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:
- –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ RabbitMQ (CloudAMQP –∏–ª–∏ –ª–æ–∫–∞–ª—å–Ω–æ–º—É)
- –°–æ–∑–¥–∞–Ω–∏–µ exchanges –∏ queues
- –ü—É–±–ª–∏–∫–∞—Ü–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π (producer)
- –ü–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π (consumer)
- Graceful shutdown
- Retry –ª–æ–≥–∏–∫–∞
"""
import asyncio
import json
import logging
from typing import Optional, Callable, Dict, Any, List
from datetime import datetime
import uuid

import aio_pika
from aio_pika import Message, DeliveryMode, ExchangeType, Connection
from aio_pika.abc import (
    AbstractConnection,
    AbstractChannel,
    AbstractExchange,
    AbstractQueue,
    AbstractIncomingMessage
)
from aio_pika.pool import Pool

from config import settings

logger = logging.getLogger(__name__)


class RabbitMQService:
    """
    Async RabbitMQ service –¥–ª—è producer –∏ consumer –æ–ø–µ—Ä–∞—Ü–∏–π

    Features:
    - Connection pooling –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    - Auto-reconnect –ø—Ä–∏ —Ä–∞–∑—Ä—ã–≤–∞—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
    - Dead Letter Queue (DLQ) –¥–ª—è failed messages
    - Priority queues support
    - Message TTL
    """

    def __init__(self):
        self.connection: Optional[AbstractConnection] = None
        self.channel: Optional[AbstractChannel] = None
        self.exchanges: Dict[str, AbstractExchange] = {}
        self.queues: Dict[str, AbstractQueue] = {}
        self._connected = False

        # Connection pool (–¥–ª—è high-load scenarios)
        self._connection_pool: Optional[Pool] = None
        self._channel_pool: Optional[Pool] = None

    async def connect(self):
        """
        –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ RabbitMQ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ —Ç–æ–ø–æ–ª–æ–≥–∏–∏ (exchanges, queues)

        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç robust connection –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
        """
        if self._connected:
            logger.info("Already connected to RabbitMQ")
            return

        try:
            logger.info(f"üîå Connecting to RabbitMQ: {settings._mask_url(settings.RABBITMQ_URL)}")

            # –°–æ–∑–¥–∞–Ω–∏–µ robust connection (auto-reconnect)
            self.connection = await aio_pika.connect_robust(
                settings.RABBITMQ_URL,
                timeout=settings.RABBITMQ_CONNECTION_TIMEOUT,
                heartbeat=settings.RABBITMQ_HEARTBEAT
            )

            # –°–æ–∑–¥–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–∞
            self.channel = await self.connection.channel()

            # QoS: prefetch_count –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å–∫–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏–π –≤–æ—Ä–∫–µ—Ä
            # –º–æ–∂–µ—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
            await self.channel.set_qos(prefetch_count=settings.PREFETCH_COUNT)

            # –°–æ–∑–¥–∞–Ω–∏–µ exchanges –∏ queues
            await self._setup_topology()

            self._connected = True
            logger.info("‚úÖ RabbitMQ connected successfully")

        except Exception as e:
            logger.error(f"‚ùå Failed to connect to RabbitMQ: {e}")
            raise

    async def _setup_topology(self):
        """
        –°–æ–∑–¥–∞–Ω–∏–µ exchanges, queues –∏ bindings

        Topology:
        Exchange (ai.tasks) ‚Üí Queue (ai.map.generation)
                            ‚Üí Queue (ai.wireframe.generation)
                            ‚Üí Queue (ai.bulk.improve)

        Dead Letter Exchange (dlx.ai.tasks) ‚Üí Queue (ai.tasks.failed)
        """

        # ==========================================
        # 1. Main Exchange –¥–ª—è AI tasks
        # ==========================================
        self.exchanges["ai.tasks"] = await self.channel.declare_exchange(
            settings.EXCHANGE_AI_TASKS,
            ExchangeType.TOPIC,  # topic –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å routing patterns
            durable=True  # –ü–µ—Ä–µ–∂–∏–≤—ë—Ç —Ä–µ—Å—Ç–∞—Ä—Ç RabbitMQ
        )
        logger.info(f"‚úÖ Exchange declared: {settings.EXCHANGE_AI_TASKS}")

        # ==========================================
        # 2. Dead Letter Exchange (DLX)
        # ==========================================
        # –°—é–¥–∞ –ø–æ–ø–∞–¥–∞—é—Ç —Å–æ–æ–±—â–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ:
        # - Expired (–ø—Ä–µ–≤—ã—Å–∏–ª–∏ TTL)
        # - Rejected with requeue=false
        # - Queue –¥–æ—Å—Ç–∏–≥–ª–∞ max-length
        dlx_exchange = await self.channel.declare_exchange(
            settings.EXCHANGE_DLX,
            ExchangeType.FANOUT,  # fanout –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –≤–æ –≤—Å–µ bound queues
            durable=True
        )
        logger.info(f"‚úÖ Dead Letter Exchange declared: {settings.EXCHANGE_DLX}")

        # ==========================================
        # 3. Dead Letter Queue
        # ==========================================
        dlq = await self.channel.declare_queue(
            "ai.tasks.failed",
            durable=True,
            arguments={
                # No TTL - —Ö–æ—Ç–∏–º —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                "x-queue-mode": "lazy"  # –°–æ—Ö—Ä–∞–Ω—è—Ç—å –Ω–∞ –¥–∏—Å–∫, –Ω–µ –≤ RAM
            }
        )
        await dlq.bind(dlx_exchange)
        self.queues["failed"] = dlq
        logger.info("‚úÖ Dead Letter Queue declared: ai.tasks.failed")

        # ==========================================
        # 4. Queue: AI Map Generation
        # ==========================================
        queue_map = await self.channel.declare_queue(
            settings.QUEUE_AI_MAP_GENERATION,
            durable=settings.QUEUE_DURABLE,
            arguments={
                "x-message-ttl": settings.MESSAGE_TTL,  # 1 hour
                "x-max-priority": 10,  # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤ 0-10
                "x-dead-letter-exchange": settings.EXCHANGE_DLX  # DLX
            }
        )

        # Bind –∫ exchange —Å routing key pattern
        await queue_map.bind(
            self.exchanges["ai.tasks"],
            routing_key="ai.task.map.#"  # Matches: ai.task.map.*, ai.task.map.*.*, etc.
        )

        self.queues["map_generation"] = queue_map
        logger.info(f"‚úÖ Queue declared and bound: {settings.QUEUE_AI_MAP_GENERATION}")

        # ==========================================
        # 5. Queue: AI Wireframe Generation (NEW)
        # ==========================================
        queue_wireframe = await self.channel.declare_queue(
            settings.QUEUE_AI_WIREFRAME_GENERATION,
            durable=settings.QUEUE_DURABLE,
            arguments={
                "x-message-ttl": settings.MESSAGE_TTL,
                "x-max-priority": 10,
                "x-dead-letter-exchange": settings.EXCHANGE_DLX
            }
        )

        await queue_wireframe.bind(
            self.exchanges["ai.tasks"],
            routing_key="ai.task.wireframe.#"
        )

        self.queues["wireframe_generation"] = queue_wireframe
        logger.info(f"‚úÖ Queue declared and bound: {settings.QUEUE_AI_WIREFRAME_GENERATION}")

        # ==========================================
        # 6. Queue: Bulk Improve (optional)
        # ==========================================
        queue_bulk = await self.channel.declare_queue(
            settings.QUEUE_AI_BULK_IMPROVE,
            durable=settings.QUEUE_DURABLE,
            arguments={
                "x-message-ttl": settings.MESSAGE_TTL,
                "x-dead-letter-exchange": settings.EXCHANGE_DLX
            }
        )

        await queue_bulk.bind(
            self.exchanges["ai.tasks"],
            routing_key="ai.task.bulk.#"
        )

        self.queues["bulk_improve"] = queue_bulk
        logger.info(f"‚úÖ Queue declared and bound: {settings.QUEUE_AI_BULK_IMPROVE}")

        # ==========================================
        # 7. –í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        # ==========================================
        logger.info(f"üìä RabbitMQ Topology created:")
        logger.info(f"   Exchanges: {len(self.exchanges)}")
        logger.info(f"   Queues: {len(self.queues)}")

    async def disconnect(self):
        """Graceful shutdown - –∑–∞–∫—Ä—ã—Ç–∏–µ –≤—Å–µ—Ö –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π"""
        if not self._connected:
            return

        try:
            logger.info("üîå Disconnecting from RabbitMQ...")

            if self.channel and not self.channel.is_closed:
                await self.channel.close()

            if self.connection and not self.connection.is_closed:
                await self.connection.close()

            self._connected = False
            logger.info("‚úÖ RabbitMQ disconnected")

        except Exception as e:
            logger.error(f"Error during disconnect: {e}")

    async def publish(
        self,
        routing_key: str,
        message_body: Dict[Any, Any],
        priority: int = 5,
        correlation_id: Optional[str] = None
    ) -> str:
        """
        –ü—É–±–ª–∏–∫–∞—Ü–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è –≤ exchange

        Args:
            routing_key: Routing key –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "ai.task.map.generation")
            message_body: –¢–µ–ª–æ —Å–æ–æ–±—â–µ–Ω–∏—è (JSON-serializable dict)
            priority: –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è (0-10, 10 = highest)
            correlation_id: ID –¥–ª—è correlation (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

        Returns:
            message_id: UUID —Å–æ–æ–±—â–µ–Ω–∏—è

        Example:
            >>> await rabbitmq_service.publish(
            ...     routing_key="ai.task.map.generation",
            ...     message_body={"job_id": "123", "user_id": 42, ...},
            ...     priority=7
            ... )
            "msg-uuid-123"
        """
        if not self._connected:
            await self.connect()

        message_id = str(uuid.uuid4())

        # Enrichment: –¥–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        enriched_body = {
            **message_body,
            "_metadata": {
                "message_id": message_id,
                "timestamp": datetime.utcnow().isoformat(),
                "producer": "usm-backend",
                "routing_key": routing_key
            }
        }

        # –°–æ–∑–¥–∞–µ–º AMQP —Å–æ–æ–±—â–µ–Ω–∏–µ
        message = Message(
            body=json.dumps(enriched_body, ensure_ascii=False).encode('utf-8'),
            delivery_mode=DeliveryMode.PERSISTENT,  # –°–æ—Ö—Ä–∞–Ω–∏—Ç—Å—è –Ω–∞ –¥–∏—Å–∫
            priority=priority,
            message_id=message_id,
            correlation_id=correlation_id or message_id,
            timestamp=datetime.utcnow(),
            content_type="application/json",
            content_encoding="utf-8"
        )

        try:
            # Publish –≤ exchange
            await self.exchanges["ai.tasks"].publish(
                message,
                routing_key=routing_key
            )

            logger.info(
                f"‚úÖ Message published: {routing_key} "
                f"(ID: {message_id}, priority: {priority})"
            )
            return message_id

        except Exception as e:
            logger.error(f"‚ùå Failed to publish message: {e}")
            raise

    async def consume(
        self,
        queue_name: str,
        callback: Callable[[Dict], Any]
    ):
        """
        –ù–∞—á–∞—Ç—å –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –æ—á–µ—Ä–µ–¥–∏

        Args:
            queue_name: –ù–∞–∑–≤–∞–Ω–∏–µ –æ—á–µ—Ä–µ–¥–∏ (–∫–ª—é—á –∏–∑ self.queues)
            callback: Async —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è
                     –î–æ–ª–∂–Ω–∞ –ø—Ä–∏–Ω–∏–º–∞—Ç—å dict –∏ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å None

        Example:
            >>> async def process_message(message_data: dict):
            ...     print(f"Processing: {message_data['job_id']}")
            ...
            >>> await rabbitmq_service.consume("map_generation", process_message)

        –ú–µ—Ö–∞–Ω–∏–∑–º –æ–±—Ä–∞–±–æ—Ç–∫–∏:
        1. –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ –æ—á–µ—Ä–µ–¥–∏
        2. –í—ã–∑–æ–≤ callback
        3. –ï—Å–ª–∏ callback —É—Å–ø–µ—à–µ–Ω ‚Üí ACK (—Å–æ–æ–±—â–µ–Ω–∏–µ —É–¥–∞–ª—è–µ—Ç—Å—è)
        4. –ï—Å–ª–∏ callback failed ‚Üí NACK + requeue (—Å–æ–æ–±—â–µ–Ω–∏–µ –≤–µ—Ä–Ω—ë—Ç—Å—è –≤ –æ—á–µ—Ä–µ–¥—å)
        5. –ï—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ retries ‚Üí –æ—Ç–ø—Ä–∞–≤–∫–∞ –≤ DLQ
        """
        if not self._connected:
            await self.connect()

        queue = self.queues.get(queue_name)
        if not queue:
            raise ValueError(f"Queue '{queue_name}' not found in self.queues")

        logger.info(f"üëÄ Starting consumer for queue: {queue_name}")

        async with queue.iterator() as queue_iter:
            async for message in queue_iter:
                # message.process() –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –¥–µ–ª–∞–µ—Ç:
                # - ACK –µ—Å–ª–∏ –±–ª–æ–∫ –≤—ã–ø–æ–ª–Ω–∏–ª—Å—è –±–µ–∑ –∏—Å–∫–ª—é—á–µ–Ω–∏–π
                # - NACK + requeue –µ—Å–ª–∏ –±—ã–ª–æ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ
                async with message.process():
                    try:
                        # –î–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è JSON
                        body = json.loads(message.body.decode('utf-8'))

                        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
                        job_id = body.get('job_id', 'N/A')
                        logger.info(f"üì® Received message from {queue_name}: job_id={job_id}")

                        # –í—ã–∑–æ–≤ callback
                        await callback(body)

                        logger.info(f"‚úÖ Message processed successfully: {message.message_id}")

                    except json.JSONDecodeError as e:
                        logger.error(f"‚ùå Invalid JSON in message: {e}")
                        # ACK –±—É–¥–µ—Ç —Å–¥–µ–ª–∞–Ω (message.process() –Ω–µ raises),
                        # —Å–æ–æ–±—â–µ–Ω–∏–µ —É–¥–∞–ª—è–µ—Ç—Å—è (–Ω–µ –º–æ–∂–µ–º –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON)

                    except Exception as e:
                        logger.error(
                            f"‚ùå Error processing message {message.message_id}: {e}",
                            exc_info=True
                        )
                        # NACK –±—É–¥–µ—Ç —Å–¥–µ–ª–∞–Ω (message.process() raises),
                        # —Å–æ–æ–±—â–µ–Ω–∏–µ –≤–µ—Ä–Ω—ë—Ç—Å—è –≤ –æ—á–µ—Ä–µ–¥—å –¥–ª—è retry
                        raise  # Important: re-raise –¥–ª—è NACK


# ==========================================
# Singleton instance
# ==========================================
rabbitmq_service = RabbitMQService()


# ==========================================
# Helper functions –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
# ==========================================

async def publish_ai_map_generation(
    job_id: str,
    user_id: int,
    requirements_text: str,
    use_enhancement: bool = True,
    priority: int = 7
) -> str:
    """
    –ü—É–±–ª–∏–∫–∞—Ü–∏—è –∑–∞–¥–∞—á–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ User Story Map

    Args:
        job_id: UUID –∑–∞–¥–∞—á–∏
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        requirements_text: –¢–µ–∫—Å—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π
        use_enhancement: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ two-stage processing
        priority: –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç (0-10, default 7 = high)

    Returns:
        message_id: ID –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
    """
    message = {
        "job_id": job_id,
        "user_id": user_id,
        "requirements_text": requirements_text,
        "use_enhancement": use_enhancement,
        "created_at": datetime.utcnow().isoformat()
    }

    return await rabbitmq_service.publish(
        routing_key="ai.task.map.generation",
        message_body=message,
        priority=priority
    )


async def publish_wireframe_generation(
    job_id: str,
    user_id: int,
    project_id: int,
    story_ids: List[int],
    style: str = "low-fidelity",
    platform: str = "web",
    priority: int = 5
) -> str:
    """
    –ü—É–±–ª–∏–∫–∞—Ü–∏—è –∑–∞–¥–∞—á–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ wireframes

    Args:
        job_id: UUID –∑–∞–¥–∞—á–∏
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        project_id: ID –ø—Ä–æ–µ–∫—Ç–∞
        story_ids: –°–ø–∏—Å–æ–∫ ID –∏—Å—Ç–æ—Ä–∏–π –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        style: –°—Ç–∏–ª—å wireframe (low-fidelity, high-fidelity, component)
        platform: –ü–ª–∞—Ç—Ñ–æ—Ä–º–∞ (web, mobile, desktop)
        priority: –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç (0-10, default 5 = normal)

    Returns:
        message_id: ID –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
    """
    message = {
        "job_id": job_id,
        "user_id": user_id,
        "project_id": project_id,
        "story_ids": story_ids,
        "style": style,
        "platform": platform,
        "created_at": datetime.utcnow().isoformat()
    }

    return await rabbitmq_service.publish(
        routing_key="ai.task.wireframe.generation",
        message_body=message,
        priority=priority
    )


async def publish_bulk_improve(
    job_id: str,
    user_id: int,
    story_ids: List[int],
    action: str,
    priority: int = 3
) -> str:
    """
    –ü—É–±–ª–∏–∫–∞—Ü–∏—è –∑–∞–¥–∞—á–∏ –º–∞—Å—Å–æ–≤–æ–≥–æ —É–ª—É—á—à–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–π

    Args:
        job_id: UUID –∑–∞–¥–∞—á–∏
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        story_ids: –°–ø–∏—Å–æ–∫ ID –∏—Å—Ç–æ—Ä–∏–π
        action: –î–µ–π—Å—Ç–≤–∏–µ (details, criteria, edge_cases)
        priority: –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç (0-10, default 3 = low)

    Returns:
        message_id: ID –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
    """
    message = {
        "job_id": job_id,
        "user_id": user_id,
        "story_ids": story_ids,
        "action": action,
        "created_at": datetime.utcnow().isoformat()
    }

    return await rabbitmq_service.publish(
        routing_key="ai.task.bulk.improve",
        message_body=message,
        priority=priority
    )
```

**–ö–ª—é—á–µ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:**

1. **Robust Connection:**
   - `connect_robust()` –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è –ø—Ä–∏ —Ä–∞–∑—Ä—ã–≤–∞—Ö
   - Heartbeat –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è

2. **Priority Queues:**
   - –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤ 0-10
   - –ë–æ–ª–µ–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –ø–µ—Ä–≤—ã–º–∏

3. **Dead Letter Queue:**
   - Failed messages –æ—Ç–ø—Ä–∞–≤–ª—è—é—Ç—Å—è –≤ DLQ
   - –ú–æ–∂–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏ manually retry

4. **Message TTL:**
   - –°–æ–æ–±—â–µ–Ω–∏—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–¥–∞–ª—è—é—Ç—Å—è —á–µ—Ä–µ–∑ 1 —á–∞—Å
   - –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π

5. **QoS (prefetch_count=1):**
   - –í–æ—Ä–∫–µ—Ä –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –∑–∞ —Ä–∞–∑
   - –†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–≥—Ä—É–∑–∫–∏ –º–µ–∂–¥—É –≤–æ—Ä–∫–µ—Ä–∞–º–∏

#### 5.3.2. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ RabbitMQ Service

–°–æ–∑–¥–∞–π—Ç–µ `test-rabbitmq-service.py`:

```python
"""
–¢–µ—Å—Ç RabbitMQ Service
"""
import asyncio
import logging
from dotenv import load_dotenv

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

load_dotenv()

async def test_publish_consume():
    """–¢–µ—Å—Ç –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –∏ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π"""
    from services.rabbitmq_service import (
        rabbitmq_service,
        publish_ai_map_generation,
        publish_wireframe_generation
    )

    print("\nüß™ Testing RabbitMQ Service...\n")

    # 1. Connect
    print("1Ô∏è‚É£ Connecting to RabbitMQ...")
    await rabbitmq_service.connect()

    # 2. Publish test message (Map Generation)
    print("\n2Ô∏è‚É£ Publishing test message (Map Generation)...")
    msg_id_1 = await publish_ai_map_generation(
        job_id="test-job-123",
        user_id=999,
        requirements_text="Test requirements",
        use_enhancement=False,
        priority=8
    )
    print(f"   Published: {msg_id_1}")

    # 3. Publish test message (Wireframe Generation)
    print("\n3Ô∏è‚É£ Publishing test message (Wireframe Generation)...")
    msg_id_2 = await publish_wireframe_generation(
        job_id="test-job-456",
        user_id=999,
        project_id=1,
        story_ids=[1, 2, 3],
        style="low-fidelity",
        platform="web",
        priority=5
    )
    print(f"   Published: {msg_id_2}")

    # 4. Test consumer
    print("\n4Ô∏è‚É£ Testing consumer (will process 2 messages)...")

    processed_count = 0
    max_messages = 2

    async def test_callback(message_data: dict):
        nonlocal processed_count
        print(f"   ‚úÖ Processed: job_id={message_data.get('job_id')}")
        processed_count += 1

        if processed_count >= max_messages:
            # Stop consuming after N messages
            raise KeyboardInterrupt("Test complete")

    try:
        # Consume from map_generation queue
        await rabbitmq_service.consume("map_generation", test_callback)
    except KeyboardInterrupt:
        print(f"\n   Processed {processed_count} messages")

    # 5. Disconnect
    print("\n5Ô∏è‚É£ Disconnecting...")
    await rabbitmq_service.disconnect()

    print("\n‚úÖ RabbitMQ Service test PASSED!\n")

if __name__ == "__main__":
    asyncio.run(test_publish_consume())
```

–ó–∞–ø—É—Å–∫:
```bash
cd backend
python test-rabbitmq-service.py
```

**–û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥:**
```
üß™ Testing RabbitMQ Service...

1Ô∏è‚É£ Connecting to RabbitMQ...
2025-12-01 10:00:00 - INFO - üîå Connecting to RabbitMQ: amqps://vrcptkqu:***@hawk-01.rmq.cloudamqp.com/vrcptkqu
2025-12-01 10:00:01 - INFO - ‚úÖ RabbitMQ connected successfully

2Ô∏è‚É£ Publishing test message (Map Generation)...
2025-12-01 10:00:02 - INFO - ‚úÖ Message published: ai.task.map.generation (ID: abc-123, priority: 8)
   Published: abc-123

3Ô∏è‚É£ Publishing test message (Wireframe Generation)...
2025-12-01 10:00:03 - INFO - ‚úÖ Message published: ai.task.wireframe.generation (ID: def-456, priority: 5)
   Published: def-456

4Ô∏è‚É£ Testing consumer (will process 2 messages)...
2025-12-01 10:00:04 - INFO - üëÄ Starting consumer for queue: map_generation
2025-12-01 10:00:05 - INFO - üì® Received message from map_generation: job_id=test-job-123
   ‚úÖ Processed: job_id=test-job-123
2025-12-01 10:00:06 - INFO - ‚úÖ Message processed successfully: abc-123

   Processed 1 messages

5Ô∏è‚É£ Disconnecting...
2025-12-01 10:00:07 - INFO - ‚úÖ RabbitMQ disconnected

‚úÖ RabbitMQ Service test PASSED!
```

