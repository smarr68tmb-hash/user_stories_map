"""
Analysis endpoints - –∞–Ω–∞–ª–∏–∑ —Å—Ö–æ–∂–µ—Å—Ç–∏ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞—Ä—Ç—ã
"""
import logging
from fastapi import APIRouter, Depends, HTTPException, Request
from sqlalchemy.orm import Session, joinedload
from slowapi import Limiter
from slowapi.util import get_remote_address

from utils.database import get_db
from models import User, Project, Activity, UserTask
from schemas import (
    ValidationResult,
    SimilarityResult,
    FullAnalysisResult,
    AnalysisRequest
)
from services import (
    validate_project_map,
    get_validation_summary,
    analyze_similarity,
    get_similarity_summary
)
from dependencies import get_current_active_user

router = APIRouter(prefix="", tags=["analysis"])
limiter = Limiter(key_func=get_remote_address)
logger = logging.getLogger(__name__)


def get_project_with_stories(project_id: int, user_id: int, db: Session) -> Project:
    """–ü–æ–ª—É—á–∞–µ—Ç –ø—Ä–æ–µ–∫—Ç —Å –ø–æ–ª–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–æ–π –≤—Å–µ—Ö —Å–≤—è–∑–µ–π"""
    project = db.query(Project)\
        .options(
            joinedload(Project.activities)
            .subqueryload(Activity.tasks)
            .subqueryload(UserTask.stories),
            joinedload(Project.releases)
        )\
        .filter(Project.id == project_id)\
        .filter(Project.user_id == user_id)\
        .first()
    
    if not project:
        raise HTTPException(status_code=404, detail="Project not found")
    
    return project


@router.get("/project/{project_id}/validate", response_model=ValidationResult)
@limiter.limit("30/minute")
def validate_project(
    project_id: int,
    request: Request,
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É User Story Map –ø—Ä–æ–µ–∫—Ç–∞
    
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç:
    - –ù–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ (Activities, Tasks, Stories)
    - –ü—É—Å—Ç—ã–µ —è—á–µ–π–∫–∏ –∏ –Ω–µ—Å–≤—è–∑–∞–Ω–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
    - –ü–æ–ª–Ω–æ—Ç—É –æ–ø–∏—Å–∞–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–π
    - –ë–∞–ª–∞–Ω—Å –º–µ–∂–¥—É —Ä–µ–ª–∏–∑–∞–º–∏
    - –î—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è –Ω–∞–∑–≤–∞–Ω–∏—è
    
    Returns:
        ValidationResult: –†–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å –æ—Ü–µ–Ω–∫–æ–π –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏
    """
    logger.info(f"Validating project {project_id} for user {current_user.id}")
    
    project = get_project_with_stories(project_id, current_user.id, db)
    
    try:
        result = validate_project_map(project, db)
        logger.info(f"Validation completed: score={result.score}, issues={len(result.issues)}")
        return result
    except Exception as e:
        logger.error(f"Validation error for project {project_id}: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Validation failed: {str(e)}")


@router.get("/project/{project_id}/analyze/similarity", response_model=SimilarityResult)
@limiter.limit("20/minute")
def analyze_project_similarity(
    project_id: int,
    request: Request,
    similarity_threshold: float = 0.7,
    duplicate_threshold: float = 0.9,
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç—å –∏—Å—Ç–æ—Ä–∏–π –≤ –ø—Ä–æ–µ–∫—Ç–µ
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç TF-IDF + Cosine Similarity –¥–ª—è –ø–æ–∏—Å–∫–∞:
    - –î—É–±–ª–∏–∫–∞—Ç–æ–≤ (—Å—Ö–æ–∂–µ—Å—Ç—å >= duplicate_threshold)
    - –ü–æ—Ö–æ–∂–∏—Ö –∏—Å—Ç–æ—Ä–∏–π (—Å—Ö–æ–∂–µ—Å—Ç—å >= similarity_threshold)
    
    Args:
        similarity_threshold: –ü–æ—Ä–æ–≥ –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –ø–æ—Ö–æ–∂–∏—Ö (0.5-1.0, default: 0.7)
        duplicate_threshold: –ü–æ—Ä–æ–≥ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ (0.8-1.0, default: 0.9)
    
    Returns:
        SimilarityResult: –ì—Ä—É–ø–ø—ã –ø–æ—Ö–æ–∂–∏—Ö –∏—Å—Ç–æ—Ä–∏–π –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    """
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    if similarity_threshold < 0.5 or similarity_threshold > 1.0:
        raise HTTPException(status_code=400, detail="similarity_threshold must be between 0.5 and 1.0")
    
    if duplicate_threshold < 0.8 or duplicate_threshold > 1.0:
        raise HTTPException(status_code=400, detail="duplicate_threshold must be between 0.8 and 1.0")
    
    if duplicate_threshold < similarity_threshold:
        raise HTTPException(
            status_code=400, 
            detail="duplicate_threshold must be >= similarity_threshold"
        )
    
    logger.info(
        f"Analyzing similarity for project {project_id} "
        f"(sim={similarity_threshold}, dup={duplicate_threshold})"
    )
    
    project = get_project_with_stories(project_id, current_user.id, db)
    
    try:
        result = analyze_similarity(project, similarity_threshold, duplicate_threshold)
        logger.info(
            f"Similarity analysis completed: "
            f"{result.stats.get('similar_groups_found', 0)} groups found"
        )
        return result
    except Exception as e:
        logger.error(f"Similarity analysis error for project {project_id}: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Analysis failed: {str(e)}")


@router.post("/project/{project_id}/analyze/full", response_model=FullAnalysisResult)
@limiter.limit("10/minute")
def full_project_analysis(
    project_id: int,
    request: Request,
    analysis_request: AnalysisRequest = None,
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–µ–∫—Ç–∞
    
    –í–∫–ª—é—á–∞–µ—Ç:
    - –í–∞–ª–∏–¥–∞—Ü–∏—é —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∫–∞—Ä—Ç—ã
    - –ê–Ω–∞–ª–∏–∑ —Å—Ö–æ–∂–µ—Å—Ç–∏ –∏—Å—Ç–æ—Ä–∏–π
    - –ì–µ–Ω–µ—Ä–∞—Ü–∏—é –æ–±—â–µ–π –æ—Ü–µ–Ω–∫–∏ –∏ —Ä–µ–∑—é–º–µ
    
    Args:
        analysis_request: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–Ω–∞–ª–∏–∑–∞ (–ø–æ—Ä–æ–≥–∏ —Å—Ö–æ–∂–µ—Å—Ç–∏, AI –∫–æ–Ω—Ñ–ª–∏–∫—Ç—ã)
    
    Returns:
        FullAnalysisResult: –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π, —Å—Ö–æ–∂–µ—Å—Ç—å—é –∏ —Ä–µ–∑—é–º–µ
    """
    # –î–µ—Ñ–æ–ª—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    if analysis_request is None:
        analysis_request = AnalysisRequest()
    
    logger.info(f"Running full analysis for project {project_id}")
    
    project = get_project_with_stories(project_id, current_user.id, db)
    
    try:
        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        validation_result = validate_project_map(project, db)
        
        # –ê–Ω–∞–ª–∏–∑ —Å—Ö–æ–∂–µ—Å—Ç–∏
        similarity_result = analyze_similarity(
            project,
            similarity_threshold=analysis_request.similarity_threshold,
            duplicate_threshold=analysis_request.duplicate_threshold
        )
        
        # TODO: AI –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤ (–µ—Å–ª–∏ include_ai_conflicts=True)
        # –ü–æ–∫–∞ –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
        
        # –†–∞—Å—á–µ—Ç –æ–±—â–µ–π –æ—Ü–µ–Ω–∫–∏
        overall_score = calculate_overall_score(validation_result, similarity_result)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∑—é–º–µ
        summary = generate_analysis_summary(
            project.name,
            validation_result,
            similarity_result,
            overall_score
        )
        
        logger.info(f"Full analysis completed: overall_score={overall_score}")
        
        return FullAnalysisResult(
            project_id=project.id,
            project_name=project.name,
            validation=validation_result,
            similarity=similarity_result,
            overall_score=overall_score,
            summary=summary
        )
        
    except Exception as e:
        logger.error(f"Full analysis error for project {project_id}: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Analysis failed: {str(e)}")


def calculate_overall_score(
    validation: ValidationResult,
    similarity: SimilarityResult
) -> int:
    """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –æ–±—â—É—é –æ—Ü–µ–Ω–∫—É –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–æ–µ–∫—Ç–∞"""
    
    # –ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –æ—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (70% –≤–µ—Å–∞)
    validation_weight = 0.7
    
    # –®—Ç—Ä–∞—Ñ –∑–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã (30% –≤–µ—Å–∞)
    similarity_weight = 0.3
    
    # –®—Ç—Ä–∞—Ñ –∑–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã: -10 –±–∞–ª–ª–æ–≤ –∑–∞ –∫–∞–∂–¥—ã–π –¥—É–±–ª–∏–∫–∞—Ç
    duplicates = similarity.stats.get("duplicates_found", 0)
    similarity_penalty = min(duplicates * 10, 30)  # –ú–∞–∫—Å–∏–º—É–º -30 –±–∞–ª–ª–æ–≤
    
    similarity_score = 100 - similarity_penalty
    
    overall = int(
        validation.score * validation_weight +
        similarity_score * similarity_weight
    )
    
    return max(0, min(100, overall))


def generate_analysis_summary(
    project_name: str,
    validation: ValidationResult,
    similarity: SimilarityResult,
    overall_score: int
) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Ä–µ–∑—é–º–µ –∞–Ω–∞–ª–∏–∑–∞"""
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
    if overall_score >= 90:
        quality = "–æ—Ç–ª–∏—á–Ω–æ–µ"
        emoji = "üåü"
    elif overall_score >= 70:
        quality = "—Ö–æ—Ä–æ—à–µ–µ"
        emoji = "‚úÖ"
    elif overall_score >= 50:
        quality = "—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ–µ"
        emoji = "‚ö†Ô∏è"
    else:
        quality = "—Ç—Ä–µ–±—É–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è"
        emoji = "‚ùå"
    
    parts = [f"{emoji} –ü—Ä–æ–µ–∫—Ç '{project_name}': –∫–∞—á–µ—Å—Ç–≤–æ {quality} ({overall_score}/100)."]
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total_stories = validation.stats.get("total_stories", 0)
    parts.append(f"–í—Å–µ–≥–æ –∏—Å—Ç–æ—Ä–∏–π: {total_stories}.")
    
    # –ü—Ä–æ–±–ª–µ–º—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    error_count = sum(1 for i in validation.issues if i.severity.value == "error")
    warning_count = sum(1 for i in validation.issues if i.severity.value == "warning")
    
    if error_count > 0:
        parts.append(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º: {error_count}.")
    if warning_count > 0:
        parts.append(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π: {warning_count}.")
    
    # –î—É–±–ª–∏–∫–∞—Ç—ã
    duplicates = similarity.stats.get("duplicates_found", 0)
    if duplicates > 0:
        parts.append(f"–ù–∞–π–¥–µ–Ω–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {duplicates}.")
    
    similar_groups = similarity.stats.get("similar_groups_found", 0) - duplicates
    if similar_groups > 0:
        parts.append(f"–ì—Ä—É–ø–ø –ø–æ—Ö–æ–∂–∏—Ö –∏—Å—Ç–æ—Ä–∏–π: {similar_groups}.")
    
    return " ".join(parts)

